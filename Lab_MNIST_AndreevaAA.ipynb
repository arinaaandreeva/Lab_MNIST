{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arinaaandreeva/Lab_MNIST/blob/main/Lab_MNIST_AndreevaAA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9ezyXzVhNF9"
      },
      "source": [
        "# Лабораторная работа №2\n",
        "**Задание:**\n",
        "\n",
        "Решить задачу классификации рукописных цифр на датасете MNIST https://www.kaggle.com/datasets/hojjatk/mnist-dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data"
      ],
      "metadata": {
        "id": "1rxDtMftqAXu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfnrwt_CmVvg"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/arinaaandreeva/Lab_MNIST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi_vXxSSEYFa",
        "outputId": "98a5daa7-06c7-4253-e9d1-c5e66e8f006e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Lab_MNIST' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8FVf-F9hMlE"
      },
      "outputs": [],
      "source": [
        "def load_mnist_images(file_path):\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "        f.read(16) # пропускаем заголовки\n",
        "        data = np.frombuffer(f.read(), dtype=np.uint8).reshape(-1, 28, 28)\n",
        "    return data\n",
        "\n",
        "def load_mnist_labels(file_path):\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "        f.read(8)# пропускаем заголовки\n",
        "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "    return labels\n",
        "\n",
        "images_path = '/content/Lab_MNIST/train-images-idx3-ubyte.gz'\n",
        "labels_path = '/content/Lab_MNIST/train-labels-idx1-ubyte.gz'\n",
        "\n",
        "# images = load_mnist_images(images_path)\n",
        "# labels = load_mnist_labels(labels_path)\n",
        "\n",
        "images_test = load_mnist_images('/content/Lab_MNIST/t10k-images-idx3-ubyte.gz')\n",
        "labels_test = load_mnist_labels('/content/Lab_MNIST/t10k-labels-idx1-ubyte.gz')\n",
        "\n",
        "# print(f\"Images shape: {images.shape}\")\n",
        "# print(f\"Labels shape: {labels.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализация данных\n",
        "def preprocess_images(images):\n",
        "    # Преобразуем размерность (N, 28, 28) -> (N, 784)\n",
        "    return images.reshape(images.shape[0], -1) / 255.0  # Нормализация в диапазон [0, 1]\n",
        "\n",
        "def one_hot_encode(labels, num_classes=10):\n",
        "    one_hot = np.zeros((labels.size, num_classes))\n",
        "    one_hot[np.arange(labels.size), labels] = 1\n",
        "    return one_hot\n"
      ],
      "metadata": {
        "id": "FmOqEn6u8oxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = preprocess_images(load_mnist_images(images_path))\n",
        "labels = load_mnist_labels(labels_path)"
      ],
      "metadata": {
        "id": "4180Uz_C8sxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Решение в виде нейронной сети, написанной на numpy"
      ],
      "metadata": {
        "id": "9a9Cz1JtqEdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear_np:\n",
        "    def __init__(self, in_features, out_features):\n",
        "        self.W = np.random.randn(in_features, out_features) * 0.01  # Инициализация весов\n",
        "        self.b = np.zeros((1, out_features))  # Инициализация смещений\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Линейная трансформация Y = X*W+b\n",
        "        self.X = X\n",
        "        self.output = np.dot(X, self.W) + self.b\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, dL_dout, learning_rate):\n",
        "        # Вычисление градиентов\n",
        "        self.dW = np.dot(self.X.T, dL_dout)  # Градиент по весам dL/dW\n",
        "        self.db = np.sum(dL_dout, axis=0, keepdims=True)  # Градиент по смещениям dL/db\n",
        "        dL_dX = np.dot(dL_dout, self.W.T)  # Градиент для входа dL/dX\n",
        "\n",
        "        # Обновление параметров\n",
        "        self.W -= learning_rate * self.dW\n",
        "        self.b -= learning_rate * self.db\n",
        "\n",
        "        return dL_dX"
      ],
      "metadata": {
        "id": "mglTnEpGqOMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        self.output = np.maximum(0, X)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, dL_dout):\n",
        "        dL_dX = dL_dout * (self.X > 0).astype(float)  # Для обратного распространения вычисляем производную ReLU и умножаем на входно йградиент\n",
        "        return dL_dX\n",
        "\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, X):\n",
        "        exp_X = np.exp(X - np.max(X, axis=1, keepdims=True)) # Стабилизирует выяисление и предотвращает переполнение\n",
        "        self.output = exp_X / np.sum(exp_X, axis=1, keepdims=True)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, dL_dout):\n",
        "        # Для задачи классификации backward Softmax обычно комбинируется с функцией потерь\n",
        "        return dL_dout  # Оставляем как есть\n"
      ],
      "metadata": {
        "id": "vvXUh0uczXg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MSELoss:\n",
        "    def forward(self, predictions, targets):\n",
        "        self.predictions = predictions\n",
        "        self.targets = targets\n",
        "        loss = np.mean((predictions - targets) ** 2)\n",
        "        return loss\n",
        "\n",
        "    def backward(self):\n",
        "      # Градиент по предсказаниям\n",
        "        dL_dpred = 2 * (self.predictions - self.targets) / self.targets.shape[0]\n",
        "        return dL_dpred\n"
      ],
      "metadata": {
        "id": "SPza5qMnzavx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.fc1 = Linear_np(input_size, hidden_size)\n",
        "        self.relu = ReLU()\n",
        "        self.fc2 = Linear_np(hidden_size, output_size)\n",
        "        self.softmax = Softmax()\n",
        "        self.loss = MSELoss()\n",
        "\n",
        "    def forward(self, X, y):\n",
        "        # Данные проходят через линейный слой - RelU- линейный слой - softMax - MSELoss\n",
        "        out = self.fc1.forward(X)\n",
        "        out = self.relu.forward(out)\n",
        "        out = self.fc2.forward(out)\n",
        "        out = self.softmax.forward(out)\n",
        "        loss = self.loss.forward(out, y)\n",
        "        return loss, out\n",
        "\n",
        "    def backward(self, learning_rate):\n",
        "        # Потери подаются на вход обратно в сеть, градиенты обновляют параменты слоев\n",
        "        dL_dout = self.loss.backward()\n",
        "        dL_dout = self.softmax.backward(dL_dout)\n",
        "        dL_dout = self.fc2.backward(dL_dout, learning_rate)\n",
        "        dL_dout = self.relu.backward(dL_dout)\n",
        "        self.fc1.backward(dL_dout, learning_rate)\n"
      ],
      "metadata": {
        "id": "0fzs1IO7zbSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X_train, y_train, X_test, y_test, epochs=30, learning_rate=0.1):\n",
        "    input_size = X_train.shape[1]\n",
        "    hidden_size = 256    # Размер скрытого слоя\n",
        "    output_size = 10   # Классы\n",
        "\n",
        "    model = NeuralNetwork(input_size, hidden_size, output_size)\n",
        "    y_train_one_hot = one_hot_encode(y_train, output_size)\n",
        "    for epoch in range(epochs):\n",
        "        loss, predictions = model.forward(X_train, y_train_one_hot)\n",
        "        model.backward(learning_rate)\n",
        "        acc = np.mean(np.argmax(predictions, axis=1) == y_train)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}, Accuracy: {acc:.2f}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "68q3kXBCzdTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(images, labels, images_test, labels_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60dQRhFw7Y7W",
        "outputId": "9583405e-f4d7-4279-caec-b477eebd0fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 0.0900, Accuracy: 0.09\n",
            "Epoch 2/30, Loss: 0.0899, Accuracy: 0.20\n",
            "Epoch 3/30, Loss: 0.0898, Accuracy: 0.34\n",
            "Epoch 4/30, Loss: 0.0897, Accuracy: 0.43\n",
            "Epoch 5/30, Loss: 0.0896, Accuracy: 0.48\n",
            "Epoch 6/30, Loss: 0.0895, Accuracy: 0.51\n",
            "Epoch 7/30, Loss: 0.0894, Accuracy: 0.54\n",
            "Epoch 8/30, Loss: 0.0893, Accuracy: 0.55\n",
            "Epoch 9/30, Loss: 0.0891, Accuracy: 0.56\n",
            "Epoch 10/30, Loss: 0.0889, Accuracy: 0.57\n",
            "Epoch 11/30, Loss: 0.0887, Accuracy: 0.57\n",
            "Epoch 12/30, Loss: 0.0884, Accuracy: 0.58\n",
            "Epoch 13/30, Loss: 0.0881, Accuracy: 0.58\n",
            "Epoch 14/30, Loss: 0.0878, Accuracy: 0.58\n",
            "Epoch 15/30, Loss: 0.0874, Accuracy: 0.58\n",
            "Epoch 16/30, Loss: 0.0869, Accuracy: 0.59\n",
            "Epoch 17/30, Loss: 0.0863, Accuracy: 0.59\n",
            "Epoch 18/30, Loss: 0.0857, Accuracy: 0.60\n",
            "Epoch 19/30, Loss: 0.0850, Accuracy: 0.61\n",
            "Epoch 20/30, Loss: 0.0841, Accuracy: 0.62\n",
            "Epoch 21/30, Loss: 0.0832, Accuracy: 0.64\n",
            "Epoch 22/30, Loss: 0.0821, Accuracy: 0.65\n",
            "Epoch 23/30, Loss: 0.0809, Accuracy: 0.67\n",
            "Epoch 24/30, Loss: 0.0796, Accuracy: 0.68\n",
            "Epoch 25/30, Loss: 0.0782, Accuracy: 0.69\n",
            "Epoch 26/30, Loss: 0.0766, Accuracy: 0.70\n",
            "Epoch 27/30, Loss: 0.0750, Accuracy: 0.71\n",
            "Epoch 28/30, Loss: 0.0732, Accuracy: 0.71\n",
            "Epoch 29/30, Loss: 0.0713, Accuracy: 0.72\n",
            "Epoch 30/30, Loss: 0.0694, Accuracy: 0.72\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.NeuralNetwork at 0x7ed027349fc0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Тесты методов forward и backward, что аутпуты этих методов совпадают с результатами в pytorch."
      ],
      "metadata": {
        "id": "yGkcJaZ7So-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy модель\n",
        "np_input = images  # (batch_size, 784)\n",
        "torch_input = torch.tensor(np_input, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 256\n",
        "output_size = 10\n",
        "np_labels_onehot = np.eye(output_size)[labels]  # OneHot метки\n",
        "np_nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
        "np_loss, np_output = np_nn.forward(np_input, np_labels_onehot)\n",
        "\n",
        "# градиент для Numpy\n",
        "np_nn.backward(learning_rate=0.1)"
      ],
      "metadata": {
        "id": "bKn118ZScFS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# параметры\n",
        "input_size = 784\n",
        "hidden_size = 256\n",
        "output_size = 10\n",
        "learning_rate = 0.1\n",
        "\n",
        "torch_input = torch.tensor(np_input, dtype=torch.float32, requires_grad=True)\n",
        "np_labels_onehot = np.eye(output_size)[labels]  # OneHot метки\n",
        "torch_labels_onehot = torch.tensor(np_labels_onehot, dtype=torch.float32)\n",
        "\n",
        "torch_nn = nn.Sequential(\n",
        "    nn.Linear(input_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, output_size),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "\n",
        "# Оптимизатор для определения lr и loss\n",
        "optimizer = optim.SGD(torch_nn.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "\n",
        "# Пример вперед (forward pass)\n",
        "torch_output = torch_nn(torch_input)\n",
        "\n",
        "# Вычисление потерь\n",
        "loss = criterion(torch_output, torch_labels_onehot)\n",
        "\n",
        "# Обратный проход (backward pass)\n",
        "optimizer.zero_grad()  # Обнуляем градиенты перед вычислением новых\n",
        "loss.backward()        # Вычисляем градиенты\n",
        "optimizer.step()       # Обновляем параметры модели с использованием learning rate\n"
      ],
      "metadata": {
        "id": "vFtmpTQDkWhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сравнение выходных данных\n",
        "print(f\"Forward разница вывода: {np.mean(np.abs(np_output - torch_output.detach().numpy())):.5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGCIoaAbeRn3",
        "outputId": "aed8e543-86ce-4c9b-c21f-4ea65b383d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward разница вывода: 0.00673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Градиенты для весов 1 слоя: {np.mean(np.abs(np_nn.fc1.dW - torch_nn[0].weight.grad.detach().numpy().T)):.5f}\")\n",
        "print(f\"Градиенты для смещений 1 слоя: {np.mean(np.abs(np_nn.fc1.db -  - torch_nn[0].bias.grad.detach().numpy().T)):.5f}\")\n",
        "print(f\"Градиенты для весов 2 слоя: {np.mean(np.abs(np_nn.fc2.dW -torch_nn[2].weight.grad.detach().numpy().T) ):.5f}\")\n",
        "print(f\"Градиенты для смещений 2 слоя: {np.mean(np.abs(np_nn.fc2.db - torch_nn[2].bias.grad.detach().numpy().T)):.5f}\")\n",
        "print(f'Разница Loss {loss - np_loss:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxYV83-tmFy6",
        "outputId": "83a53d86-562c-4312-be1a-af6b1b7d9d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Градиенты для весов 1 слоя: 0.00024\n",
            "Градиенты для смещений 1 слоя: 0.00077\n",
            "Градиенты для весов 2 слоя: 0.00291\n",
            "Градиенты для смещений 2 слоя: 0.00790\n",
            "Разница Loss 0.00017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qpRq7XglqcHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vx7njVxFqcFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yuq-dcdnqcCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDxKzNAkqan4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.cuda(), with torch.cuda.amp.autocast\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# model.to(device)"
      ],
      "metadata": {
        "id": "F_oUsjd6p0m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"Для forward\"\"\"\n",
        "# np_input = images  # (batch_size, 784)\n",
        "# torch_input = torch.tensor(np_input, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# input_size = 784\n",
        "# hidden_size = 256\n",
        "# output_size = 10\n",
        "\n",
        "# # Numpy модель\n",
        "# np_layer1 = Linear(input_size, hidden_size)\n",
        "# np_layer2 = Linear(hidden_size, output_size)\n",
        "# hidden_output_np = np_layer1.forward(np_input)\n",
        "# final_output_np = np_layer2.forward(hidden_output_np)\n",
        "\n",
        "# # PyTorch модель\n",
        "# torch_layer1 = torch.nn.Linear(input_size, hidden_size)\n",
        "# torch_layer2 = torch.nn.Linear(hidden_size, output_size)\n",
        "\n",
        "# # Сопоставление параметров Numpy и PyTorch\n",
        "# torch_layer1.weight.data = torch.tensor(np_layer1.W.T, dtype=torch.float32)\n",
        "# torch_layer1.bias.data = torch.tensor(np_layer1.b.flatten(), dtype=torch.float32)\n",
        "# #обновляем bias с использованием torch.no_grad(), Скопируем bias из numpy\n",
        "# with torch.no_grad():\n",
        "#     torch_layer1.bias.copy_(torch.tensor(np_layer1.b.flatten(), dtype=torch.float32))\n",
        "# torch_layer2.weight.data = torch.tensor(np_layer2.W.T, dtype=torch.float32)\n",
        "# torch_layer2.bias.data = torch.tensor(np_layer2.b.flatten(), dtype=torch.float32)\n",
        "\n",
        "# torch_input = torch.tensor(np_input, dtype=torch.float32, requires_grad=True)  # PyTorch input\n",
        "# hidden_output_torch = torch_layer1(torch_input)\n",
        "# final_output_torch = torch_layer2(hidden_output_torch)\n",
        "\n",
        "# # Вывод разницы между результатами\n",
        "# abs_difference = np.abs(final_output_np - final_output_torch.detach().numpy())\n",
        "# rel_difference = abs_difference\n",
        "# print(\"разница между выходными данными:\", np.mean(rel_difference))\n",
        "# print(\"Относительная разница между выходными данными:\", np.mean(rel_difference/ np.abs(final_output_np)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g5sbZmw6zujD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # PyTorch модель\n",
        "# torch_input = torch.tensor(np_input, dtype=torch.float32, requires_grad=True)\n",
        "# torch_labels_onehot = torch.tensor(np_labels_onehot, dtype=torch.float32)\n",
        "\n",
        "# torch_nn = nn.Sequential(\n",
        "#     nn.Linear(input_size, hidden_size),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(hidden_size, output_size),\n",
        "#     nn.Softmax(dim=1)\n",
        "# )\n",
        "\n",
        "# torch_output = torch_nn(torch_input)\n",
        "# torch_loss = torch.mean((torch_output - torch_labels_onehot) ** 2)\n",
        "\n",
        "# # Сравнение выходных данных\n",
        "# print(f\"Forward разница вывода: {np.mean(np.abs(np_output - torch_output.detach().numpy())):.5f}\")\n",
        "# print(f\"Forward относительная разница вывода: {np.mean(np.abs((np_output - torch_output.detach().numpy())/np_output)):.5f}\")"
      ],
      "metadata": {
        "id": "MCWPERBPdK3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Правила следующие:\n",
        "* нужно представить решение в виде нейронной сети, написанной на numpy, и обученной с помощью алгоритма градиентного спуска;\n",
        "* нейронная сеть должна состоять из двух линейных слоев, активаций relu и softmax, и mse лосса - каждый оформлен в виде класса с методами forward и backward;\n",
        "* нельзя пользоваться автоградиентом (pytorch, numpy), за исключением тестов. Градиенты должны считаться вручную по алгоритму обратного распространения ошибки,\n",
        "используя аналитические формулы производных;\n",
        "* решение считается валидным, если оно достигает аккураси больше 50%.\n",
        "* для каждого слоя должны быть реализованы тесты методов forward и backward. Нужно убедиться, что аутпуты этих методов совпадают с результатами в pytorch.\n",
        "\n",
        "Критерии оценивания:\n",
        "+ базовая 6 баллов\n",
        "+ за линейный forward + backward - +1 балл\n",
        "+ за классы активации softmax и relu - +1 балл\n",
        "+ за класс MSELoss - +1 балл (не CrossEntropy - так интереснее)\n",
        "+ +1 балл, если реализованы тесты и есть численное совпадение с результатами pytorch\n",
        "- Плохое оформление кода - нет классов и разделений на функции - -1 балл\n",
        "- Слишком медленный код - -1 балл. (если код можно ускорить в 10 раз)\n",
        "- CrossEntropy вместо MSELoss - -1 балл.\n",
        "\n",
        "Дедлайн: 5 декабря 23:59"
      ],
      "metadata": {
        "id": "VI1FxNpxqRKG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ieFxHvu7qRhA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}